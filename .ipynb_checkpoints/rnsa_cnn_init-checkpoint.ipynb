{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f762db01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydicom in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (2.3.1)\n",
      "Requirement already satisfied: pillow in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (8.4.0)\n",
      "Requirement already satisfied: pylibjpeg-libjpeg in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (1.3.2)\n",
      "Requirement already satisfied: pylibjpeg in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (1.4.0)\n",
      "Requirement already satisfied: python-gdcm in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (3.0.20)\n",
      "Requirement already satisfied: seaborn in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (0.11.2)\n",
      "Requirement already satisfied: matplotlib in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (3.4.3)\n",
      "Requirement already satisfied: SciPy in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (1.7.1)\n",
      "Requirement already satisfied: scikit-image in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (0.18.3)\n",
      "Requirement already satisfied: python-magic in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (0.4.27)\n",
      "Requirement already satisfied: tensorflow-io in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (0.29.0)\n",
      "Requirement already satisfied: plotly in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (5.11.0)\n",
      "Requirement already satisfied: pip in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (21.2.4)\n",
      "Requirement already satisfied: install in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (1.3.5)\n",
      "Requirement already satisfied: opencv-python in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: tensorflow in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.22 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from pylibjpeg-libjpeg) (1.22.4)\n",
      "Requirement already satisfied: pandas>=0.23 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from scikit-image) (2.6.3)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from scikit-image) (2021.7.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.29.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow-io) (0.29.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from plotly) (8.1.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: packaging in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: setuptools in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.19.6)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.51.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.1.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (22.12.6)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/xueweichen/Downloads/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydicom pillow pylibjpeg-libjpeg pylibjpeg python-gdcm seaborn matplotlib SciPy scikit-image python-magic tensorflow-io plotly pip install opencv-python tensorflow \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066a046b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.16.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 11:14:42.139443: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#%reload_ext signature\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import scipy.ndimage\n",
    "from skimage import morphology\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "from sklearn.cluster import KMeans\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.tools import FigureFactory as FF\n",
    "from plotly.graph_objs import *\n",
    "init_notebook_mode(connected=True) \n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0635e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_image = pydicom.read_file('train_images/10006/1459541791.dcm')\n",
    "u = []\n",
    "for s in glob(\"train_images/10006/*.dcm\"):\n",
    "    print(\"image file %s\", s)\n",
    "    img_test = pydicom.read_file(s)    \n",
    "    u.append(img_test.pixel_array)\n",
    "    #plt.imshow(img_test.pixel_array)\n",
    "    print(img_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee8e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_id = tfio.image.dicom_tags.PatientsAge\n",
    "tag_value = tfio.image.decode_dicom_data(image_bytes,tag_id)\n",
    "print(tag_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d0b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_id = tfio.image.dicom_tags.PatientsSex\n",
    "tag_value = tfio.image.decode_dicom_data(image_bytes,tag_id)\n",
    "print(f\"PatientsSex : {tag_value.numpy().decode('UTF-8')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9af698",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c2d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a5b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6abe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"cancer\"][train_df[\"patient_id\"] == 10006][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f03cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da99e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 8))\n",
    "train_df.isna().mean().plot(kind=\"barh\")\n",
    "plt.title(\"Missing value rates\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6226d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340df177",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = glob(\"train_images/*/*.dcm\")\n",
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ec4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf02d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image0 = pydicom.read_file(train_images[0])\n",
    "print(train_image0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ad9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image0_array = train_image0.pixel_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ce4c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_image0_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e62c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_image0_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca0a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_image0_array)\n",
    "print(train_image0_array.min())\n",
    "print(train_image0_array.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761376d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cf https://towardsdatascience.com/medical-image-pre-processing-with-python-d07694852606\n",
    "# Five steps of preprocessing: \n",
    "# Transforming to HU, Removing Noises, Tilt Correction, Crop Images and Padding.\n",
    "def transform_to_hu(medical_image, image):\n",
    "    intercept = medical_image.RescaleIntercept\n",
    "    slope = medical_image.RescaleSlope\n",
    "    hu_image = image * slope + intercept\n",
    "\n",
    "    return hu_image\n",
    "def window_image(image, window_center, window_width):\n",
    "    img_min = window_center - window_width // 2\n",
    "    img_max = window_center + window_width // 2\n",
    "    window_image = image.copy()\n",
    "    window_image[window_image < img_min] = img_min\n",
    "    window_image[window_image > img_max] = img_max\n",
    "    \n",
    "    return window_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e090ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f055e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(file_path, display=False):\n",
    "    medical_image = pydicom.read_file(file_path)\n",
    "    image = medical_image.pixel_array\n",
    "    \n",
    "    hu_image = transform_to_hu(medical_image, image)\n",
    "    # I am not sure why some scans have multiple window_center values while some have only one\n",
    "    # So naively I just take the average of their values\n",
    "    # TODO: to better understand the mammography images...\n",
    "    window_center = np.array(medical_image.WindowCenter).mean()\n",
    "    window_width = np.array(medical_image.WindowWidth).mean()\n",
    "    windowed_image = window_image(hu_image, window_center, window_width) \n",
    "    \n",
    "    segmentation = morphology.dilation(windowed_image, np.ones((1, 1)))\n",
    "    labels, label_nb = ndimage.label(segmentation)\n",
    "    \n",
    "    label_count = np.bincount(labels.ravel().astype(np.int))\n",
    "    label_count[0] = 0\n",
    "\n",
    "    mask = labels == label_count.argmax()\n",
    " \n",
    "    mask = morphology.dilation(mask, np.ones((1, 1)))\n",
    "    mask = ndimage.morphology.binary_fill_holes(mask)\n",
    "    mask = morphology.dilation(mask, np.ones((3, 3)))\n",
    "    masked_image = mask * windowed_image\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6782cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"train_images/10006/1459541791.dcm\"\n",
    "medical_image = pydicom.read_file(file_path)\n",
    "image = medical_image.pixel_array\n",
    "\n",
    "#hu_image = transform_to_hu(medical_image, image)\n",
    "#window_center = medical_image.WindowCenter\n",
    "#window_width = medical_image.WindowWidth\n",
    "#windowed_image = window_image(hu_image, window_center, window_width) \n",
    "np.array(medical_image.WindowCenter)[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf22296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tilt correction\n",
    "# not sure if it is useful for breast cancer as the original data is for brain ct\n",
    "# tbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5d851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, display = False):\n",
    "    mask = image == 0\n",
    "    coords = np.array(np.nonzero(~mask))\n",
    "    top_left = np.min(coords, axis = 1)\n",
    "    bottom_right = np.max(coords, axis = 1)\n",
    "    cropped_image = image[top_left[0]:bottom_right[0],\n",
    "                         top_left[1]:bottom_right[1]]\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883c68cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pad(image, new_height=512, new_width=512):\n",
    "    height, width = image.shape\n",
    "\n",
    "    final_image = np.zeros((new_height, new_width))\n",
    "\n",
    "    pad_left = int((new_width - width) // 2)\n",
    "    pad_top = int((new_height - height) // 2)\n",
    "    \n",
    "    \n",
    "    # Replace the pixels with the image's pixels\n",
    "    final_image[pad_top:pad_top + height, pad_left:pad_left + width] = image\n",
    "    \n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c92c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_image = transform_to_hu( train_image0, train_image0_array)\n",
    "windowed_image0 = window_image(hu_image, train_image0.WindowCenter, train_image0.WindowWidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a583f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(windowed_image0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2616bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = \"train_images/10006/1459541791.dcm\"\n",
    "removed_noise_image0 = remove_noise(\"train_images/10006/1459541791.dcm\", display = False)\n",
    "removed_noise_image0 = remove_noise(patient_all_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95a1de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image0 = crop_image(removed_noise_image0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650483b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_image0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77023644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# added_pad_image0 = add_pad(cropped_image0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f28ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cropped_image0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8452eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(removed_noise_image0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18134c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_image0_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb9144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap the above functions up into one master func\n",
    "def preprocess_dicom(file):\n",
    "    removed_noise_image0 = remove_noise(file, display = False)\n",
    "    cropped_image = crop_image(removed_noise_image0)\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3798d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf37e3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"patient_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f202190",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_patient_in_train_csv = []\n",
    "for patient in all_patients:\n",
    "    if patient not in str(train_df[\"patient_id\"]):\n",
    "        if_patient_in_train_csv.append(False)\n",
    "    else:\n",
    "        if_patient_in_train_csv.append(True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de4f786",
   "metadata": {},
   "outputs": [],
   "source": [
    "if_patient_not_in_train_csv = [not x for x in if_patient_in_train_csv]\n",
    "patient_in_train_csv = np.array(all_patients)[if_patient_in_train_csv]\n",
    "patients_not_in_train_csv = np.array(all_patients)[if_patient_not_in_train_csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec23af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"patient ids as image file folder matched up with train_df.csv :\", patient_in_train_csv, \"the matched ids in total\", patient_in_train_csv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2a0626",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"patient ids not matched in the image folder and train_df.csv: \", patients_not_in_train_csv, \"the not matched ids in total\", patients_not_in_train_csv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4b00be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "all_patients = os.listdir(\"train_images/\")\n",
    "y = []\n",
    "X = []\n",
    "### WARNING: temporary solution. to only get the matched data trained\n",
    "for patient in patient_in_train_csv:\n",
    "    patient_all_files = glob(\"train_images/\"+ patient + \"/*.dcm\")\n",
    "    for patient_file in patient_all_files:        \n",
    "        patient_array = preprocess_dicom(patient_file)\n",
    "        X.append(patient_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9856d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df['cancer'][train_df[\"patient_id\"].astype(str) == (patient_in_train_csv[0])].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8571f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(patient_in_train_csv)\n",
    "#train_df.loc[train_df['patient_id'].astype(str).isin(patient_in_train_csv)]        \n",
    "#y_patient = train_df[\"cancer\"][str(train_df[\"patient_id\"]) == patient][0]\n",
    "#y.append(y_patient)\n",
    "for patient in patient_in_train_csv:\n",
    "    patient_all_files = glob(\"train_images/\"+ patient + \"/*.dcm\")\n",
    "    for patient_file in patient_all_files:  \n",
    "        y_tmp = train_df['cancer'][train_df[\"patient_id\"].astype(str) == (patient_in_train_csv[0])].unique()\n",
    "        y.append(y_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ce4c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_array = np.array(X)\n",
    "y_array = np.array(y)\n",
    "print(X_array.shape)\n",
    "print(y_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f2782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naively split the train and test data\n",
    "# using the train test split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_array,y_array ,\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.25, \n",
    "                                   shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c8f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize features\n",
    "img_size = 224 # not sure why. but copy from https://www.analyticsvidhya.com/blog/2020/10/create-image-classification-model-python-keras/\n",
    "X_train_resize = []\n",
    "X_val_resize = []\n",
    "for x in X_train:\n",
    "    resized_arr = cv2.resize(x, (img_size, img_size)) # Reshaping images to preferred size\n",
    "    X_train_resize.append(resized_arr)\n",
    "for x in X_val:\n",
    "    resized_arr = cv2.resize(x, (img_size, img_size)) # Reshaping images to preferred size\n",
    "    X_val_resize.append(resized_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "X_train = np.array(X_train_resize)/255 # not sure why but naively use the online code from https://www.analyticsvidhya.com/blog/2020/10/create-image-classification-model-python-keras/\n",
    "X_train = X_train.reshape(-1, img_size, img_size, 1)\n",
    "\n",
    "X_val = np.array(X_val_resize)/255 # not sure why but naively use the online code from https://www.analyticsvidhya.com/blog/2020/10/create-image-classification-model-python-keras/\n",
    "X_val = X_val.reshape(-1, img_size, img_size, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fbbc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f02a010",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20feb005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be43a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e30c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,3)))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cb51195",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Adam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vn/7vh0yxsj5js3z8lj0p09cq1w0000gn/T/ipykernel_89233/3236546273.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Adam' is not defined"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.000001)\n",
    "model.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb7af4dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vn/7vh0yxsj5js3z8lj0p09cq1w0000gn/T/ipykernel_89233/2963801867.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs = 500 , validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff2d355a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vn/7vh0yxsj5js3z8lj0p09cq1w0000gn/T/ipykernel_89233/2162498383.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(500)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd4f89b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
